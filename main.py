import cv2
import matplotlib.pyplot as plt
import numpy as np
import os
import time


def generate_light_calibration_template(paper_image_path, save_path=None):
    """Use a photo image taken from a plain white paper to produce a calibration template. The template will be used to enhance 
    the light intensity of each pixel in input image to a same level

    :param paper_image_path: the path of white paper image
    :param save_path: the save path of produced template, if none, then do not save template
    :return: template image
    :rtype: numpy.ndarray
    """
    paper_image = cv2.imread(paper_image_path)
    # print(paper_image.shape)
    h, w = paper_image.shape[0:2]
    template_resize = cv2.resize(paper_image, (int(w / 4), int(h / 4)), cv2.INTER_CUBIC)
    # print(template_resize.shape)
    for i in range(5):
        template_resize = cv2.medianBlur(template_resize, 7)
    for i in range(10):
        template_resize = cv2.GaussianBlur(template_resize, (7, 7), 2)
    template_resize_back = cv2.resize(template_resize, (w, h), cv2.INTER_CUBIC)
    template = 1 / (template_resize_back / 255)

    if save_path is not None:
        cv2.imwrite(os.path.join(save_path, "template.jpg"), template)

    return template

def generate_template_patch(image, previous_patch, offset_x, offset_y):
    """Generate the patch in next input image for concatenate
    
    :param image: input image
    :param previous_patch: previous generated image patch
    :param offset_x: offset of patch in the vertical direction
    :param offset_y: offset of patch in the horizontal direction
    :return: generated patch, coordinate of patch left-upper corner point
    :rtype: numpy.ndarray, tuple
    """
    # 从大patch中分割出一个小patch来进行匹配, 通过匹配结果定位下一个用于连结模板的patch的位置
    calibrate_patch = previous_patch[previous_patch.shape[0] - kCalibrationHeight:previous_patch.shape[0], int((kPatchWidth - kCalibrationWidth) / 2):int((kPatchWidth + kCalibrationWidth) / 2)].copy()
    calibrate_patch = cv2.medianBlur(calibrate_patch, 9)
    # calibrate_patch = calibrate_patch.astype(np.float32)
    # calibrate_patch -= calibrate_patch.mean()
    # 如果一切正常进行得到的匹配点(减去之前累积的误差)
    supposed_coor = (kCropCoordinate[0] - kCalibrationHeight + offset_x, kCropCoordinate[1] + int((kPatchWidth - kCalibrationWidth) / 2) + offset_y)
    # 限制搜索范围在加减kSearchRange的区域内
    search_image = image[supposed_coor[0] - kSearchRange:supposed_coor[0] + kCalibrationHeight + kSearchRange, supposed_coor[1] - kSearchRange:supposed_coor[1] + kPatchWidth + kSearchRange].copy()
    # search_image = search_image.astype(np.float32)
    # search_image -= search_image.mean()
    # search_image = cv2.medianBlur(search_image, 9)
    match_result = cv2.matchTemplate(search_image, calibrate_patch, cv2.TM_CCORR_NORMED)
    match_coor = np.unravel_index(np.argmax(match_result), match_result.shape)
    
    # 正常的匹配结果应为(kSearchRange, kSearchRange), 计算偏差量
    delta_x = match_coor[0] - kSearchRange
    delta_y = match_coor[1] - kSearchRange
    # 通过总偏差量得到下一个patch在下一张图中的定位位置
    updated_coor = (kCropCoordinate[0] + offset_x + delta_x, kCropCoordinate[1] + offset_x + delta_x)
    new_patch = image[updated_coor[0]:updated_coor[0] + kPassHeight, updated_coor[1]:updated_coor[1] + kPatchWidth]
    
    return new_patch, delta_x, delta_y

def apply_light_calibration(image, template):
    """Calibrate the light condition of input image

    :param image: input image
    :param template: template generated by function generate_light_calibration_template
    :return: calibrated image
    :rtype: numpy.ndarray
    """
    image = image.astype(np.float64)
    template = template.astype(np.float64)
    output = image * template
    output[np.where(output > 255)] = 255
    output = output.astype(np.uint8)
    return output

def largest_indices(ary, n):
    """Returns the n largest indices from a numpy array."""
    flat = ary.flatten()
    indices = np.argpartition(flat, -n)[-n:]
    indices = indices[np.argsort(-flat[indices])]
    return np.unravel_index(indices, ary.shape)

def save_diff_image(image1, image2, save_path=None):
    """Return and save the diff-image between image1 and image2
    """
    diff = (image1 - image2 + 127).astype(np.uint8)
    if save_path is not None:
        cv2.imwrite(save_path, diff)
    return diff

def save_diff_image_2(image1, image2, save_path=None):
    """Return and save the diff-image between image1 and image2
    """
    a = image1.astype(np.int32)
    b = image2.astype(np.int32)
    # diff = a - b
    # diff = diff - diff.min()
    # diff = (diff / diff.max() * 255).astype(np.uint8)
    diff = np.abs(a - b)
    diff = diff.astype(np.uint8)
    if save_path is not None:
        cv2.imwrite(save_path, diff)
    
    return diff

def ink_detection(img):
    img = img[100:-100, 100:-100]
    img_blur = cv2.medianBlur(img, 9)
    img_blur = cv2.medianBlur(img, 9)
    img_blur[np.where(img_blur <= 100)] = 0
    img_blur[np.where(img_blur > 100)] = 1
    gray_img = np.zeros(img.shape[0:2], dtype=np.uint8)
    binary = np.bitwise_or(img_blur[:, :, 0], img_blur[:, :, 1])
    binary = np.bitwise_or(img_blur[:, :, 2], binary)
    gray_img[np.where(binary == 1)] = 255

    contours, _ = cv2.findContours(gray_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
    for cnt in contours:
        area = cv2.contourArea(cnt)
        perimeter = cv2.arcLength(cnt, True)
        if perimeter == 0:
            continue
        circularity = (4 * np.pi * area) / perimeter ** 2
        area_hull = cv2.contourArea(cv2.convexHull(cnt))
        if area_hull == 0:
            continue
        convexity = area / area_hull

    return 0



if __name__ == "__main__":
    # Constants
    kPaperImagePath = "20201027/exp8000.bmp"
    # kPassHeight = 1464
    kPassHeight = 1494
    kPatchWidth = 3000
    kTemplateHeight = 417 + 4 * kPassHeight
    kCropCoordinate = (825, 548)
    kCalibrationHeight = int(kPassHeight / 3)
    kCalibrationWidth = 3000
    # kStartImagePath = "20201027/exp10000_good/Image_20201027160149832.bmp"
    kStartImagePath = "20201105/good_01_exp13000_1pass/Image_20201105140551709.bmp"
    kBlockShape = (6, 6)
    kNumberOfBlockForVoting = 10
    kSearchRange = 50
    # ink offset
    # kMovingOffset = 2972
    # water offset
    # kMovingOffset = 2954
    # block offset
    # kMovingOffset = 0
    kMovingOffset = None
    kTemplateFolder = "20201105/good_01_exp13000_1pass/"
    # kDetectionFolder = "20201105/01ink_marks/"
    kDetectionFolder = "20201105/01block/"

    time_data = []
    for i in range(1):
        start = time.time()
        light_calibration_template = generate_light_calibration_template(kPaperImagePath)
        queue = os.listdir(kTemplateFolder)[6:]
        queue2 = queue.copy()

        time_interval = []
        
        # Template synthesis
        start_image = cv2.imread(kStartImagePath)
        start_image = apply_light_calibration(start_image, light_calibration_template)
        start_patch = start_image[kCropCoordinate[0]:kCropCoordinate[0] + kPassHeight, kCropCoordinate[1]:kCropCoordinate[1] + kPatchWidth]
        complete_template = start_patch.copy()
        previous_patch = start_patch.copy()
        offset_x = 0
        offset_y = 0
        point_1 = time.time()
        time_interval.append(point_1 - start)
        # previous_coor = kCropCoordinate
        patch_count = 1
        for i in queue:
            if complete_template.shape[0] > kTemplateHeight + kPassHeight:
                break
            else:
                stage_start = time.time()
                next_image = cv2.imread(kTemplateFolder + i)
                next_image = apply_light_calibration(next_image, light_calibration_template)
                next_patch, delta_x, delta_y = generate_template_patch(next_image, previous_patch, offset_x, offset_y)
                cv2.imwrite("patch_" + str(patch_count) + ".png", next_patch)
                offset_x += delta_x
                offset_y += delta_y
                previous_patch = next_patch
                complete_template = np.concatenate((complete_template, next_patch), axis=0)
                queue2.remove(i)
                # print(delta_x)
                # print(delta_y)
                patch_count += 1
                stage_end = time.time()
                time_interval.append(stage_end - stage_start)
        
        cv2.imwrite("template1116.jpg", complete_template[0:kTemplateHeight + kPassHeight])
        complete_template = complete_template[0:kTemplateHeight + kPassHeight]

        # padding the template
        gray_padding = np.ones((complete_template.shape[0], 200, 3), dtype=np.uint8)
        gray_padding *= 127
        complete_template = np.concatenate([gray_padding, complete_template, gray_padding], axis=1)
        end = time.time()
        time_interval.append(end - start)
        # print(time_interval)
        time_data.append(time_interval)
    # time_data = np.array(time_data)
    # print(time_data.mean(axis=0))
    print("Template synthesis done!")
    queue2_count = 0



    # Template matching
    # for i in queue2:
    #     # print(i)
    #     next_image = cv2.imread(kTemplateFolder + i)
    #     next_image = apply_light_calibration(next_image, light_calibration_template)
    #     next_patch = next_image[kCropCoordinate[0]:kCropCoordinate[0] + kPassHeight, kCropCoordinate[1]:kCropCoordinate[1] + kPatchWidth]
    #     # Block the patch into several blocks(n*m)
    #     gradient_matrix = np.zeros(kBlockShape)
    #     partitioned_patch = [[] for i in range(kBlockShape[0])]
    #     k = 0
    #     for m in np.array_split(next_patch, kBlockShape[0], axis=0):
    #         for n in np.array_split(m, kBlockShape[1], axis=1):
    #             partitioned_patch[k].append(n)
    #         k += 1
        
    #     row = 0
    #     for m in np.array_split(next_patch, kBlockShape[0], axis=0):
    #         column = 0
    #         # print(m.shape)
    #         for n in np.array_split(m, kBlockShape[1], axis=1):
    #             absX = cv2.convertScaleAbs(cv2.Sobel(n, cv2.CV_16S, 1, 0))
    #             absY = cv2.convertScaleAbs(cv2.Sobel(n, cv2.CV_16S, 0, 1))
    #             gradient_matrix[row, column] = (cv2.addWeighted(absX, 0.5, absY, 0.5, 0)).sum() / absX.size
    #             column += 1
    #             # print(n.shape)
    #         row += 1
        
    #     n_largest_blocks = largest_indices(gradient_matrix, kNumberOfBlockForVoting)
    #     for i in range(kNumberOfBlockForVoting):
    #         patch = partitioned_patch[n_largest_blocks[0][i]][n_largest_blocks[1][i]]
    #         patch_match_result = cv2.matchTemplate(complete_template, patch, cv2.TM_CCOEFF_NORMED)
    #         patch_match_coor = np.unravel_index(np.argmax(patch_match_result), patch_match_result.shape)
    #         match_patch = complete_template[patch_match_coor[0]:patch_match_coor[0] + patch.shape[0], patch_match_coor[1]:patch_match_coor[1] + patch.shape[1]]
    #         save_diff_image(patch, match_patch, "diff_test/" + str(i) + ".jpg")
    #         # print(patch_match_coor)
    #         x_calibration = 0
    #         for j in range(n_largest_blocks[0][i]):
    #             x_calibration += partitioned_patch[j][n_largest_blocks[1][i]].shape[0]
    #         y_calibration = 0
    #         for j in range(n_largest_blocks[1][i]):
    #             y_calibration += partitioned_patch[n_largest_blocks[0][i]][j].shape[1]
    #         calibrated_coor = (patch_match_coor[0] - x_calibration, patch_match_coor[1] - y_calibration)
    #         print(calibrated_coor)


    print(patch_count)
    # queue2 = os.listdir("20201105/01water")[0:]
    # queue2 = os.listdir(kDetectionFolder)
    
    template_matching_time = []
    for i in queue2:
        # 计算匹配开始点(纵坐标)
        start = time.time()
        k_period = (patch_count * kPassHeight - kTemplateHeight) // kTemplateHeight
        h1 = patch_count * kPassHeight - (k_period + 1) * kTemplateHeight
        if kMovingOffset is not None:
            k_period = (kMovingOffset + queue2_count * kPassHeight) // kTemplateHeight
            h1 = kMovingOffset + queue2_count * kPassHeight - k_period * kTemplateHeight
        
        # next_image = cv2.imread(kDetectionFolder + i)
        next_image = cv2.imread(kTemplateFolder + i)
        next_image = apply_light_calibration(next_image, light_calibration_template)
        next_patch = next_image[kCropCoordinate[0]:kCropCoordinate[0] + kPassHeight, kCropCoordinate[1]:kCropCoordinate[1] + kPatchWidth]
        # cv2.imwrite("patch_cali_1.jpg", next_patch)
        # exit()
        initial_coor = np.array([h1, 200], dtype=np.int64)
        search_range = [initial_coor[0] - kSearchRange, initial_coor[1] - kSearchRange, initial_coor[0] + next_patch.shape[0] + kSearchRange, initial_coor[1] + next_patch.shape[1] + kSearchRange]
        if initial_coor[0] - kSearchRange < 0:
            search_range = [0, initial_coor[1] - kSearchRange, initial_coor[0] + next_patch.shape[0] + kSearchRange, initial_coor[1] + next_patch.shape[1] + kSearchRange]
        search_template = complete_template[search_range[0]:search_range[2], search_range[1]:search_range[3]]
        whole_match_result = cv2.matchTemplate(search_template, next_patch, cv2.TM_CCOEFF_NORMED)
        whole_match_coor = np.unravel_index(np.argmax(whole_match_result), whole_match_result.shape)
        match_whole_patch = search_template[whole_match_coor[0]:whole_match_coor[0] + next_patch.shape[0], whole_match_coor[1]:whole_match_coor[1] + next_patch.shape[1]]
        # diff = save_diff_image_2(next_patch, match_whole_patch)
        # ink_detection(diff)
        end = time.time()
        template_matching_time.append(end - start)
        # for test
        cv2.imwrite("best_template_diff/Source_img_" + str(queue2_count) + ".png", match_whole_patch)
        cv2.imwrite("best_template_diff/Match_img_" + str(queue2_count) + ".png", next_patch)
        save_diff_image_2(next_patch, match_whole_patch, "diff_result/good/20201117_directdiff" + str(queue2_count) + ".png")
        print(i)
        # print(queue2_count)

        # Block the patch into several blocks(n*m)
        # partitioned_patch = [[] for i in range(kBlockShape[0])]
        # partitioned_patch_shape = np.ones((kBlockShape[0], kBlockShape[1], 2), dtype=np.int32)

        # k = 0
        # for m in np.array_split(next_patch, kBlockShape[0], axis=0):
        #     j = 0
        #     for n in np.array_split(m, kBlockShape[1], axis=1):
        #         partitioned_patch[k].append(n)
        #         partitioned_patch_shape[k, j] = n.shape[0:2]
        #         j += 1
        #     k += 1


        # coor_shift = []
        # complete_diff = []
        # k = 0
        # for i in partitioned_patch:
        #     j = 0
        #     partitioned_patch_diff = []
        #     for patch in i:
        #         # print(patch.shape)
        #         initial_coor = np.array([h1, 200], dtype=np.int64)
        #         delta_x = partitioned_patch_shape[0:k, j, 0].sum()
        #         delta_y = partitioned_patch_shape[k, 0:j, 1].sum()
        #         patch_h = partitioned_patch_shape[k, j, 0]
        #         patch_w = partitioned_patch_shape[k, j, 1]
        #         initial_coor[0] += delta_x
        #         initial_coor[1] += delta_y
        #         search_range = (initial_coor[0] - kSearchRange, initial_coor[1] - kSearchRange, initial_coor[0] + patch_h + kSearchRange, initial_coor[1] + patch_w + kSearchRange)
        #         sub_search_template = complete_template[search_range[0]:search_range[2], search_range[1]:search_range[3]]
        #         patch_match_result = cv2.matchTemplate(sub_search_template, patch, cv2.TM_CCOEFF_NORMED)
        #         patch_match_coor = np.unravel_index(np.argmax(patch_match_result), patch_match_result.shape)
        #         coor_shift.append(np.array(patch_match_coor) - np.array([20, 20], dtype=np.float32))
        #         match_patch = sub_search_template[patch_match_coor[0]:patch_match_coor[0] + patch.shape[0], patch_match_coor[1]:patch_match_coor[1] + patch.shape[1]]
        #         partitioned_patch_diff.append(save_diff_image_2(patch, match_patch))
        #         j += 1
        #     row_together = np.concatenate(partitioned_patch_diff, axis=1)
        #     k += 1
        #     # print(row_together.shape)
        #     complete_diff.append(row_together)
        # print("done")
        
        # together_diff = np.concatenate(complete_diff, axis=0)
        # cv2.imwrite("directdiff_patches" + str(queue2_count) + ".png", together_diff)
        # # print(coor_shift)
        # print(np.array(coor_shift).mean(axis=0))
        patch_count += 1
        queue2_count += 1
        if queue2_count == 7:
            break

        # break
    
    time_data = np.array(template_matching_time)
    print(time_data.mean())






    
